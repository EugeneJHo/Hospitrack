{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2a2f956",
   "metadata": {},
   "source": [
    "##Data transformation file for chicago and midwest enriched datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ec6c78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import math\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9455f2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _safe_float(x):\n",
    "    try: return float(x)\n",
    "    except: return None\n",
    "\n",
    "def _round_half_up(x):\n",
    "    return int(math.floor(x + 0.5))\n",
    "\n",
    "# overall mortality +- 5 points max to total quality points\n",
    "def _parse_overall_mortality_blocks(r):\n",
    "    \"\"\"\n",
    "    Returns (label, signed_blocks).\n",
    "    blocks = round_half_up(percent/20) clamped to [0,5]\n",
    "    +blocks if 'better', -blocks if 'worse', 0 if missing/unclear.\n",
    "    \"\"\"\n",
    "    direction = (r.get(\"detail_mortality_overall_direction\") or \"\").strip().lower()\n",
    "    pct = _safe_float(r.get(\"detail_mortality_overall_percent\"))\n",
    "    text = (r.get(\"detail_mortality_overall_text\") or \"\").strip().lower()\n",
    "\n",
    "    if direction not in (\"better\", \"worse\"):\n",
    "        if \"better\" in text: direction = \"better\"\n",
    "        elif \"worse\" in text: direction = \"worse\"\n",
    "\n",
    "    if pct is None:\n",
    "        m = re.search(r\"(\\d+(?:\\.\\d+)?)\\s*%\", text)\n",
    "        if m: pct = _safe_float(m.group(1))\n",
    "\n",
    "    if direction in (\"better\", \"worse\") and pct is not None:\n",
    "        blocks = _round_half_up(pct / 20.0)\n",
    "        blocks = max(0, min(5, blocks))\n",
    "        signed = blocks if direction == \"better\" else -blocks\n",
    "        pct_label = _round_half_up(pct)\n",
    "        return f\"{pct_label}% {direction} (±{blocks})\", signed\n",
    "    return \"mortality not used\", 0\n",
    "\n",
    "# Add quality points function, append quality points column and also related vairables column\n",
    "def add_quality_points(in_path: str, out_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Adds to CSV:\n",
    "      - ed_minutes_rating  (10..1 / 'wait time rating not available' / 'points not available')\n",
    "      - detail_overall_patient_rating_points ('10'..'4' or 'patient rating not available')\n",
    "      - mortality_overall_contribution (label)\n",
    "      - total_quality_points (int) = ED + Patient ± OverallMortalityBlocks\n",
    "    ED rating rules:\n",
    "      • Baseline ED minutes = row 2 if valid; else min valid ED in file.\n",
    "      • 10 points at baseline; -1 point per +30 minutes.\n",
    "      • If ED minutes or wait_minutes are 0/blank → label 'wait time rating not available' and impute mean ED rating into total.\n",
    "    Patient rating:\n",
    "      • very good=10, good=9, above average=8, average=7, below average=6, poor=5, very poor=4.\n",
    "      • Blank/unrecognized → label 'patient rating not available', impute mean into total.\n",
    "    Overall mortality:\n",
    "      • From overall direction/percent or text; converts to ±blocks of 20% (max ±5). Missing → 0.\n",
    "    \"\"\"\n",
    "    with open(in_path, newline=\"\", encoding=\"utf-8\") as f:\n",
    "        rows = list(csv.DictReader(f))\n",
    "\n",
    "    # minimum ED minutes, assume it is in row 2\n",
    "    baseline = _safe_float(rows[1].get(\"detail_avg_time_in_ed_minutes\")) if len(rows) >= 2 else None\n",
    "    if baseline is None or baseline <= 0:\n",
    "        candidates = []\n",
    "        for rr in rows:\n",
    "            ed = _safe_float(rr.get(\"detail_avg_time_in_ed_minutes\"))\n",
    "            wt = _safe_float(rr.get(\"wait_minutes\"))\n",
    "            if ed is not None and ed > 0 and not (wt == 0):\n",
    "                candidates.append(ed)\n",
    "        baseline = min(candidates) if candidates else 0.0\n",
    "\n",
    "    pr_map = {\n",
    "        \"very good\": 10, \"good\": 9, \"above average\": 8,\n",
    "        \"average\": 7, \"below average\": 6, \"poor\": 5, \"very poor\": 4\n",
    "    }\n",
    "\n",
    "    ed_valid, patient_valid = [], []\n",
    "    prelim = []\n",
    "    for r in rows:\n",
    "        # ED rating (10 at baseline; -1 per +30 mins)\n",
    "        ed_minutes = _safe_float(r.get(\"detail_avg_time_in_ed_minutes\"))\n",
    "        wait_minutes = _safe_float(r.get(\"wait_minutes\"))\n",
    "        if (ed_minutes is None) or (wait_minutes is None) or (ed_minutes == 0) or (wait_minutes == 0):\n",
    "            ed_label, ed_points = \"wait time rating not available\", None\n",
    "        else:\n",
    "            delta = max(0.0, ed_minutes - baseline)\n",
    "            pts = 10 - int(delta // 30)\n",
    "            if pts > 0:\n",
    "                ed_label, ed_points = str(pts), pts\n",
    "                ed_valid.append(pts)\n",
    "            else:\n",
    "                ed_label, ed_points = \"points not available\", 0\n",
    "\n",
    "        # Patient rating\n",
    "        pr_text = (r.get(\"detail_overall_patient_rating\") or \"\").strip().lower()\n",
    "        if pr_text in pr_map:\n",
    "            pr_points = pr_map[pr_text]\n",
    "            pr_label = str(pr_points)\n",
    "            patient_valid.append(pr_points)\n",
    "        else:\n",
    "            pr_label, pr_points = \"patient rating not available\", None\n",
    "\n",
    "        # Overall mortality ±blocks\n",
    "        mort_label, mort_signed = _parse_overall_mortality_blocks(r)\n",
    "\n",
    "        prelim.append((r, ed_label, ed_points, pr_label, pr_points, mort_label, mort_signed))\n",
    "\n",
    "    ed_mean = _round_half_up(sum(ed_valid) / len(ed_valid)) if ed_valid else 0\n",
    "    patient_mean = _round_half_up(sum(patient_valid) / len(patient_valid)) if patient_valid else 0\n",
    "\n",
    "    fieldnames = list(rows[0].keys()) if rows else []\n",
    "    for c in [\"ed_minutes_rating\",\n",
    "              \"detail_overall_patient_rating_points\",\n",
    "              \"mortality_overall_contribution\",\n",
    "              \"total_quality_points\"]:\n",
    "        if c not in fieldnames: fieldnames.append(c)\n",
    "\n",
    "    out_rows = []\n",
    "    for r, ed_label, ed_points, pr_label, pr_points, mort_label, mort_signed in prelim:\n",
    "        if ed_points is None: ed_points = ed_mean\n",
    "        if pr_points is None: pr_points = patient_mean\n",
    "        total = int(ed_points) + int(pr_points) + int(mort_signed)\n",
    "        r[\"ed_minutes_rating\"] = ed_label\n",
    "        r[\"detail_overall_patient_rating_points\"] = pr_label\n",
    "        r[\"mortality_overall_contribution\"] = mort_label\n",
    "        r[\"total_quality_points\"] = str(total)\n",
    "        out_rows.append(r)\n",
    "\n",
    "    with open(out_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        w = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "        w.writeheader(); w.writerows(out_rows)\n",
    "\n",
    "# ---------- COMPLAINT-ADJUSTED (per-request) ----------\n",
    "# map complaint→most relevant condition-specific mortality column(s)\n",
    "_COMPLAINT_TO_COL = {\n",
    "    \"chest pain\": [\"detail_mortality_heart_attack_percent\"],\n",
    "    \"heart attack\": [\"detail_mortality_heart_attack_percent\", \"detail_mortality_overall_percent\"],\n",
    "    \"slurred speech\": [\"detail_mortality_stroke_percent\"],\n",
    "    \"facial droop\": [\"detail_mortality_stroke_percent\"],\n",
    "    \"stroke\": [\"detail_mortality_stroke_percent\"],\n",
    "    \"shortness of breath\": [\"detail_mortality_heart_failure_percent\", \"detail_mortality_pneumonia_percent\"],\n",
    "    \"trouble breathing\": [\"detail_mortality_heart_failure_percent\", \"detail_mortality_pneumonia_percent\"],\n",
    "    \"cough\": [\"detail_mortality_pneumonia_percent\"],\n",
    "    \"fever\": [\"detail_mortality_pneumonia_percent\"],\n",
    "    \"default\": [\"detail_mortality_overall_percent\"],\n",
    "}\n",
    "\n",
    "def _pick_mort_col(complaint: str):\n",
    "    c = (complaint or \"\").strip().lower()\n",
    "    for k, cols in _COMPLAINT_TO_COL.items():\n",
    "        if k != \"default\" and k in c:\n",
    "            return cols\n",
    "    return _COMPLAINT_TO_COL[\"default\"]\n",
    "\n",
    "def _mortality_points_0to5(pct: float | None) -> int | None:\n",
    "    \"\"\"Lower mortality is better. 0–20%→5, 20–40%→4, 40–60%→3, 60–80%→2, 80–100%→1. Missing→None.\"\"\"\n",
    "    if pct is None: return None\n",
    "    if pct < 0: pct = 0.0\n",
    "    if pct > 100: pct = 100.0\n",
    "    band = int(pct // 20)       # 0..5\n",
    "    pts = max(0, 5 - band)      # 5..0\n",
    "    return pts\n",
    "\n",
    "def complaint_points_for_row(row: dict, complaint: str) -> tuple[int, str]:\n",
    "    \"\"\"\n",
    "    For the given row and complaint, return (points_0to5, explain_string).\n",
    "    Missing mortality for all candidate columns → (0, 'complaint mortality not used').\n",
    "    \"\"\"\n",
    "    for col in _pick_mort_col(complaint):\n",
    "        pct = _safe_float(row.get(col))\n",
    "        pts = _mortality_points_0to5(pct)\n",
    "        if pts is None:\n",
    "            continue\n",
    "        # valid mortality; 0 points if very high, but still 'used'\n",
    "        return pts, f\"{col}→{(f'{pct:.1f}%' if pct is not None else 'NA')} ⇒ +{pts}\"\n",
    "    return 0, \"complaint mortality not used\"\n",
    "\n",
    "def rank_with_complaint(enriched_path: str, complaint: str, top_k: int = 10) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Reads the enriched CSV (after add_quality_points) and returns complaint-adjusted totals\n",
    "    WITHOUT modifying the CSV: complaint_total = base total_quality_points + complaint_mortality_points (0..5).\n",
    "    \"\"\"\n",
    "    with open(enriched_path, newline=\"\", encoding=\"utf-8\") as f:\n",
    "        rows = list(csv.DictReader(f))\n",
    "\n",
    "    out = []\n",
    "    for r in rows:\n",
    "        base_total = _safe_float(r.get(\"total_quality_points\")) or 0.0\n",
    "        cmp_pts, cmp_explain = complaint_points_for_row(r, complaint)\n",
    "        adj_total = int(base_total) + int(cmp_pts)\n",
    "        out.append({\n",
    "            \"name\": r.get(\"name\",\"\"),\n",
    "            \"city\": r.get(\"city\",\"\"),\n",
    "            \"complaint\": complaint,\n",
    "            \"complaint_mortality_points\": cmp_pts,\n",
    "            \"complaint_mortality_explain\": cmp_explain,\n",
    "            \"complaint_total_quality_points\": adj_total\n",
    "        })\n",
    "\n",
    "    out.sort(key=lambda x: x[\"complaint_total_quality_points\"], reverse=True)\n",
    "    return out[:max(1, top_k)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a329a499",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Call and create a new transformed staging_chicago_enriched.csv called chicago_er_tranformed.csv\n",
    "add_quality_points(\n",
    "    in_path=\"staging_chicago_enriched.csv\",\n",
    "    out_path=\"chicago_er_transformed.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "835f2248",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Call and create a new tranformed midwest_hospitals_enriched.csv called midwest_er_transformed.csv\n",
    "add_quality_points(\n",
    "    in_path=\"midwest_hospitals_enriched.csv\",\n",
    "    out_path=\"midwest_er_transformed.csv\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vsc-py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
